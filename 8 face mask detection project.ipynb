{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c44f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c5ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08de1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9af31939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 992 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9853WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 0.0406 - accuracy: 0.9853 - val_loss: 0.0483 - val_accuracy: 0.9819\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.0349 - accuracy: 0.9866\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.0337 - accuracy: 0.9891\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.0459 - accuracy: 0.9837\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.0333 - accuracy: 0.9884\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.0335 - accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.0312 - accuracy: 0.9903\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.0293 - accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.0295 - accuracy: 0.9893\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.0336 - accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16200742d68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dataset=ImageDataGenerator(rescale=1/255,width_shift_range=0.1,shear_range=0.2,horizontal_flip=True,zoom_range=0.2)\n",
    "test_dataset=ImageDataGenerator(rescale=1/255)\n",
    "train=train_dataset.flow_from_directory(\"C:\\\\Users\\\\user\\\\Downloads\\\\Face Mask Dataset\\\\Train\",target_size=(64,64),batch_size=32,class_mode=\"binary\")\n",
    "test=test_dataset.flow_from_directory(\"C:\\\\Users\\\\user\\\\Downloads\\\\Face Mask Dataset\\\\Test\",target_size=(64,64),batch_size=32,class_mode=\"binary\")\n",
    "model.fit(train,steps_per_epoch=100,epochs=10,validation_data=test,validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4159fcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "WithMask\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_img=image.load_img(\"C:\\\\Users\\\\user\\\\Downloads\\\\Face Mask Dataset\\\\Prediction\\\\WithMask\\\\141.png\",target_size=(64,64))\n",
    "#image to array\n",
    "test_img=image.img_to_array(test_img)\n",
    "test_img=np.expand_dims(test_img,axis=0)\n",
    "result=model.predict(test_img)\n",
    "print(result[0][0])\n",
    "if result[0][0]==1:\n",
    "    prediction=\"WithoutMask\"\n",
    "else :\n",
    "    prediction=\"WithMask\"\n",
    "print(prediction)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed0c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "WithoutMask\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_img1=image.load_img(\"C:\\\\Users\\\\user\\\\Downloads\\\\Face Mask Dataset\\\\Prediction\\\\WithoutMask\\\\380.png\",target_size=(64,64))\n",
    "#image to array\n",
    "test_img1=image.img_to_array(test_img1)\n",
    "test_img1=np.expand_dims(test_img1,axis=0)\n",
    "result=model.predict(test_img1)\n",
    "print(result[0][0])\n",
    "if result[0][0]==1:\n",
    "    prediction=\"WithoutMask\"\n",
    "else :\n",
    "    prediction=\"WithMask\"\n",
    "print(prediction)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f07f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception v3 also done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b3ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskdetect():    \n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    cap=cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "    while True:\n",
    "        ret,pic=cap.read()\n",
    "        if ret==True: \n",
    "            gray_pic=cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv\\\\haarcascade_frontalface_default.xml\")\n",
    "            faces=face_cascade.detectMultiScale(gray_pic,1.1,4)\n",
    "            for (x,y,w,h) in faces:\n",
    "\n",
    "                face=pic[y:y+h,x:x+w,:]\n",
    "                face=cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n",
    "                face=cv2.resize(face,(64,64))\n",
    "                test_img=image.img_to_array(face)\n",
    "                test_img=np.expand_dims(test_img,axis=0)\n",
    "                prediction=model.predict(test_img)\n",
    "                if prediction[0][0]==0:\n",
    "                    result='mask'\n",
    "                    cv2.rectangle(pic,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    cv2.rectangle(pic,(x,(y-w//4)),((x+h//2),y),(255,0,0),-1)\n",
    "                    cv2.putText(pic,\"mask\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.45,(255,255,255),1)\n",
    "                    playsound(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\project 4 face mask detection\\\\Welcome.mp3\")\n",
    "                else:\n",
    "                    result='Without Mask'\n",
    "                    cv2.rectangle(pic,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                    cv2.rectangle(pic,(x,(y-w//4)),((x+h//2),y),(0,0,255),-1)\n",
    "                    cv2.putText(pic,\"No Mask\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.45,(255,255,255),1)\n",
    "                    playsound(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\project 4 face mask detection\\\\No_Mask.mp3\")\n",
    "                print(result)\n",
    "            cv2.imshow(\"Face mask detection\",pic) \n",
    "            \n",
    "            if cv2.waitKey(20)==ord('q'):\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92caa0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbc38dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk,Image\n",
    "window=tk.Tk()\n",
    "window.title(\"Face Mask Detection\")    \n",
    "window.config(bg=\"light blue\")\n",
    "\n",
    "labelbg=Label(window)\n",
    "img=ImageTk.PhotoImage(Image.open(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\project 4 face mask detection\\\\bg.png\"),master=window)\n",
    "labelbg.configure(image=img)\n",
    "labelbg.Image=img\n",
    "labelbg.place(x=0,y=0)\n",
    "labelbg.lower()\n",
    "\n",
    "\n",
    "l=Label(window,text=\"Face Mask Detection\",font=(\"Good Times\",30),bg=\"light green\",fg=\"blue\") # for title\n",
    "l.pack(side=TOP,fill=X)\n",
    "\n",
    "l1=tk.Label(window,text=\"PLEASE PUT ON A MASK\",font=(\"Candles\",18),bg=\"black\",fg=\"white\")\n",
    "l1.place(x=300,y=200)\n",
    "l2=tk.Label(window,text=\"AND KEEP SAFE SOCIAL DISTANCING.....!\",font=(\"Candles\",18),bg=\"black\",fg=\"white\")\n",
    "l2.place(x=400,y=300)\n",
    "l2=tk.Label(window,text=\"Please enter the above button for mask detection\",font=(\"Comic Sans MS\",25),bg=\"green\",fg=\"white\")\n",
    "l2.pack(side=BOTTOM,fill=X)\n",
    "\n",
    "\n",
    "def abort():\n",
    " window.destroy()\n",
    "\n",
    "button1=tk.Button(window,text=\"ENTER\",command=maskdetect,font=(\"Ethnocentric\",22))\n",
    "button1.place(x=380,y=580)\n",
    "\n",
    "lo=Button(window,text=\"Log out\",command=abort,font=(\"Hollywood Hills\",18),bg=\"white\",fg=\"black\")\n",
    "lo.place(x=900,y=80)\n",
    "\n",
    "window.geometry(\"1920x1080\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22236a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from keras.preprocessing import image\n",
    "# cap = cv2.VideoCapture(0)  \n",
    "# while (cap.isOpened()):  \n",
    "#     ret,img = cap.read()\n",
    "#     if ret==True:\n",
    "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv\\\\haarcascade_frontalface_default.xml\")\n",
    "#         faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "#         for (x, y, w, h) in faces:\n",
    "#             roi_color=gray[y:y+h,x:x+w,:]\n",
    "#             roi_color=cv2.cvtColor(roi_color,cv2.COLOR_BGR2RGB)\n",
    "#             resizedimg= cv2.resize(roi_color,(64,64))\n",
    "#             test_img=image.img_to_array(resizedimg)\n",
    "#             test_img=np.expand_dims(test_img,axis=0)\n",
    "#             result=model.predict(test_img)\n",
    "#             print(result[0][0])\n",
    "#             if result[0][0]==1:\n",
    "#                 #prediction=\"WithoutMask\"\n",
    "#                 cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) \n",
    "#             else :\n",
    "#                 #prediction=\"WithMask\"\n",
    "#                 cv2.rectangle(img, (x, y), (x+w, y+h), (0,255, 0), 2) \n",
    "#         #print(prediction)      \n",
    "#             cv2.imshow(\"Video\",img)   \n",
    "#     if cv2.waitKey(1)==ord('q') :    #when press q it will quit,ord will give the ASCII of q # you can also use & 0xFF=ord('q') if any error comes\n",
    "#          break  \n",
    "# cap.release()  \n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88273c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# img=cv2.imread(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv images\\\\23.jpg\")\n",
    "# gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv\\\\haarcascade_frontalface_default.xml\") #importing the file having face features\n",
    "# faces=face_cascade.detectMultiScale(gray,1.1,4) #taking 1 pixel and search around 4 neighbours of it #face recognition\n",
    "# for (x,y,w,h) in faces:                 #1.1 is scaling factor\n",
    "#     cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #for face\n",
    "#     roi_gray=gray[y:y+h,x:x+w]\n",
    "#     roi_color=img[y:y+h,x:x+w]\n",
    "#     face=face_cascade.detectMultiScale(roi_gray) \n",
    "#     for (ex,ey,ew,eh) in face:\n",
    "#         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "# cv2.imshow(\"Output\",img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5179f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# from keras.preprocessing import image\n",
    "# cap=cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "# while (cap.isOpened()):\n",
    "#     ret,img1=cap.read()\n",
    "#     if ret==True: \n",
    "#         gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#         face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv\\\\haarcascade_frontalface_default.xml\")\n",
    "#         faces=face_cascade.detectMultiScale(gray,1.1,4)\n",
    "#         for (x,y,w,h) in faces:\n",
    "#             roi_gray=gray[y:y+h,x:x+w]\n",
    "#             roi_img=img[y:y+h,x:x+w]\n",
    "#             #face=face_cascade.detectMultiScale(roi_gray)\n",
    "#             face = cv2.resize(roi_img, (64,64))\n",
    "#             test_img1=image.img_to_array(face)\n",
    "#             test_img1=np.expand_dims(test_img1,axis=0)\n",
    "#             result=model.predict(test_img1)\n",
    "#             print(result[0][0])\n",
    "#             if result[0][0]==1:\n",
    "#                 prediction=\"WithoutMask\"\n",
    "#             else :\n",
    "#                 prediction=\"WithMask\"\n",
    "#             print(prediction)\n",
    "#         cv2.imshow(\"Mask_detection\",img)\n",
    "#         ret,img2=cap.read()\n",
    "#         img1=img2\n",
    "#         if cv2.waitKey(1)==ord('q'):\n",
    "#             break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e28c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from keras.preprocessing import image\n",
    "# cap = cv2.VideoCapture(0)  \n",
    "# while (cap.isOpened()):  \n",
    "#     ret,img = cap.read()\n",
    "#     if ret==True:\n",
    "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv\\\\haarcascade_frontalface_default.xml\")\n",
    "#         for (x, y, w, h) in faces:\n",
    "#             roi_color=img[y:y+h,x:x+w]\n",
    "#             face = face_cascade.detectMultiScale(roi_color, 1.1, 4)\n",
    "#             faces = cv2.resize(face,(64,64))\n",
    "#             test_img=image.img_to_array(faces)\n",
    "#             test_img=np.expand_dims(test_img,axis=0)\n",
    "#             result=model.predict(test_img)\n",
    "#             print(result[0][0])\n",
    "#             if result[0][0]==1:\n",
    "#                 #prediction=\"WithoutMask\"\n",
    "#                 cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) \n",
    "#             else :\n",
    "#                 #prediction=\"WithMask\"\n",
    "#                 cv2.rectangle(img, (x, y), (x+w, y+h), (0,255, 0), 2) \n",
    "#         #print(prediction)      \n",
    "#         cv2.imshow(\"Video\",img)   \n",
    "#     if cv2.waitKey(1)==ord('q') :    #when press q it will quit,ord will give the ASCII of q # you can also use & 0xFF=ord('q') if any error comes\n",
    "#          break  \n",
    "# cap.release()  \n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328670c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from keras.preprocessing import image\n",
    "# cap = cv2.VideoCapture(0)  \n",
    "# while (cap.isOpened()):  \n",
    "#     ret,img = cap.read()\n",
    "#     if ret==True:\n",
    "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv\\\\haarcascade_frontalface_default.xml\")\n",
    "#         for (x, y, w, h) in faces:\n",
    "#             roi_color=img[y:y+h,x:x+w]\n",
    "#             face = face_cascade.detectMultiScale(roi_color, 1.1, 4)\n",
    "#             faces = cv2.resize(face,(64,64))\n",
    "#             test_img=image.img_to_array(faces)\n",
    "#             test_img=np.expand_dims(test_img,axis=0)\n",
    "#             result=model.predict(test_img)\n",
    "#             print(result[0][0])\n",
    "#             if result[0][0]==1:\n",
    "#                 #prediction=\"WithoutMask\"\n",
    "#                 cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) \n",
    "#             else :\n",
    "#                 #prediction=\"WithMask\"\n",
    "#                 cv2.rectangle(img, (x, y), (x+w, y+h), (0,255, 0), 2) \n",
    "#         #print(prediction)      \n",
    "#         cv2.imshow(\"Video\",img)   \n",
    "#     if cv2.waitKey(1)==ord('q') :    #when press q it will quit,ord will give the ASCII of q # you can also use & 0xFF=ord('q') if any error comes\n",
    "#          break  \n",
    "# cap.release()  \n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d589f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# cap=cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "# while True:\n",
    "#     ret,pic=cap.read()\n",
    "#     if ret==True: \n",
    "#         gray_pic=cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\user\\\\Desktop\\\\asap\\\\opencv\\\\haarcascade_frontalface_default.xml\")\n",
    "#         faces=face_cascade.detectMultiScale(gray_pic,1.1,4)\n",
    "#         for (x,y,w,h) in faces:\n",
    "            \n",
    "#             face=pic[y:y+h,x:x+w,:]\n",
    "#             face=cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n",
    "#             face=cv2.resize(face,(64,64))\n",
    "#             test_img=image.img_to_array(face)\n",
    "#             test_img=np.expand_dims(test_img,axis=0)\n",
    "#             prediction=model.predict(test_img)\n",
    "#             if prediction[0][0]==0:\n",
    "#                 result='mask'\n",
    "#                 cv2.rectangle(pic,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#                 cv2.rectangle(pic,(x,(y-w//4)),((x+h//2),y),(255,0,0),-1)\n",
    "#                 cv2.putText(pic,\"mask\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.45,(255,255,255),1)\n",
    "#             else:\n",
    "#                 result='Without Mask'\n",
    "#                 cv2.rectangle(pic,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "#                 cv2.rectangle(pic,(x,(y-w//4)),((x+h//2),y),(0,0,255),-1)\n",
    "#                 cv2.putText(pic,\"No Mask\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.45,(255,255,255),1)\n",
    "#             print(result)\n",
    "                \n",
    "#         cv2.imshow(\"Mask_detection\",pic)\n",
    "#         if cv2.waitKey(20)==ord('q'):\n",
    "#             break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import required Libraries\n",
    "# from tkinter import *\n",
    "# from PIL import Image, ImageTk\n",
    "# import cv2\n",
    "\n",
    "# # Create an instance of TKinter Window or frame\n",
    "# win = Tk()\n",
    "\n",
    "# # Set the size of the window\n",
    "# win.geometry(\"700x350\")\n",
    "# win.title(\"Face Mask Detector\")\n",
    "# win.config(bg=\"black\")\n",
    "# # Create a Label to capture the Video frames\n",
    "# label =Label(win)\n",
    "# label.grid(row=0, column=0)\n",
    "# cap= cv2.VideoCapture(0)\n",
    "\n",
    "# # Define function to show frame\n",
    "# def show_frames():\n",
    "#    # Get the latest frame and convert into Image\n",
    "#    cv2image= cv2.cvtColor(cap.read()[1],cv2.COLOR_BGR2RGB)\n",
    "#    img = Image.fromarray(cv2image)\n",
    "#    # Convert image to PhotoImage\n",
    "#    imgtk = ImageTk.PhotoImage(image = img)\n",
    "#    label.imgtk = imgtk\n",
    "#    label.configure(image=imgtk)\n",
    "#    # Repeat after an interval to capture continiously\n",
    "#    label.after(20, show_frames)\n",
    "\n",
    "# show_frames()\n",
    "# win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "# import tkinter as tk\n",
    "# from PIL import ImageTk,Image\n",
    "# window=tk.Tk()\n",
    "# window.title(\"Face mask detection\")    \n",
    "# window.config(bg=\"light blue\")\n",
    "\n",
    "# l1=tk.Label(window,text=\"\",font=(\"times new roman\",18),bg=\"green\",fg=\"white\")\n",
    "# l1.place(x=10,y=200)\n",
    "\n",
    "\n",
    "# def abort():\n",
    "#  window.destroy()\n",
    "\n",
    "# img = Image.open(\"C:\\\\Users\\\\user\\\\Desktop\\\\mask.jpg\")\n",
    "# img2=ImageTk.PhotoImage(img)\n",
    "# w=img.width\n",
    "# h=img.height\n",
    "# label = Label(window,image=img2)\n",
    "# label.pack()\n",
    "\n",
    "# button1=tk.Button(window,text=\"SUBMIT\",command=maskdetect)\n",
    "# button1.place(x=250,y=600)\n",
    "\n",
    "# lo=Button(window,text=\"Log out\",command=abort,font=(\"times new roman\",18),bg=\"black\",fg=\"white\")\n",
    "# lo.place(x=600,y=70)\n",
    "\n",
    "# window.geometry('%dx%d+0+0' % (w,h))\n",
    "# window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deca53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7937c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
